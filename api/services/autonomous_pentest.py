"""
Autonomous Pentesting (Governed) v4.5.0
Planner + Approval Gate + Executor + Reporting
"""

import asyncio
import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional
from collections import defaultdict

from api.config import settings
from api.services.executor_engine import ToolExecutor
from api.services.llm_integration import safe_llm_call
from api.services.cases import update_case_status

logger = logging.getLogger(__name__)

# In-memory state store for pentest jobs (for MVP; use Redis/DB in production)
_pentest_state: Dict[str, Dict[str, Any]] = {}
_approval_queue: Dict[str, Dict[str, Any]] = defaultdict(list)


# ---------------------------------------------------------------------------
# Loading helpers (policy, context)
# ---------------------------------------------------------------------------

def _load_pentest_policy(policy_id: str) -> Dict[str, Any]:
    """Carga policy de pentest. Placeholder: usar DB/archivo en producci√≥n."""
    policy_path = Path(settings.PROJECT_ROOT) / "config" / "pentest_policies.json"
    if policy_path.exists():
        try:
            data = json.loads(policy_path.read_text())
            for item in data:
                if item.get("policy_id") == policy_id:
                    return item
        except Exception as exc:  # pragma: no cover - fallback a defaults
            logger.warning("No se pudo leer policy file: %s", exc)
    return {
        "policy_id": policy_id,
        "allowed_actions": ["recon", "vuln_scan", "config_review"],
        "forbidden_actions": ["exploit", "password_bruteforce", "dos"],
        "scope": {"domains": [], "ips": [], "cloud": [], "excluded": []},
        "intensity": "SAFE",
        "human_approval_required": True,
    }


def _load_case_context(case_id: str) -> Dict[str, Any]:
    """Carga contexto de caso. Placeholder en memoria."""
    return {
        "case_id": case_id,
        "discovered_hosts": [],
        "previous_findings": [],
    }


# ---------------------------------------------------------------------------
# Planner
# ---------------------------------------------------------------------------

async def plan_pentest_with_llm(
    pentest_id: str,
    case_id: str,
    policy_id: str,
    objectives: Optional[str] = None,
    targets: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """Invoca LLM planner y valida el plan contra la policy."""
    policy = _load_pentest_policy(policy_id)
    context = _load_case_context(case_id)

    # Validar targets contra policy scope
    if targets:
        _validate_targets_against_policy(targets, policy)

    prompt = _build_planner_prompt(
        pentest_id=pentest_id,
        case_id=case_id,
        policy=policy,
        context=context,
        objectives=objectives,
        targets=targets,
    )

    llm_raw = await safe_llm_call(prompt=prompt, timeout=settings.LLM_STUDIO_TIMEOUT, provider_hint="local")

    try:
        plan = json.loads(llm_raw)
    except Exception as exc:
        logger.error("Planner LLM devolvi√≥ JSON inv√°lido: %s", exc)
        raise

    _validate_plan_against_policy(plan, policy)
    
    # Persist plan to filesystem
    _persist_plan(pentest_id, case_id, plan, policy, targets)
    
    return plan


def _build_planner_prompt(pentest_id: str, case_id: str, policy: Dict[str, Any], context: Dict[str, Any], objectives: Optional[str], targets: Optional[Dict[str, Any]] = None) -> str:
    """Crea prompt seguro para Planner (JSON expected)."""
    targets_str = json.dumps(targets) if targets else "not specified"
    return (
        "You are MCP Autonomous Pentest Planner Agent.\n"
        "ROLE: Decide pentesting steps safely within strict policy.\n"
        "Never exceed scope. Never exploit. Never brute-force. Never DoS. Always log and produce evidence paths.\n"
        "Return JSON with keys: tasks[], escalation_required (bool).\n"
        f"PENTEST_ID: {pentest_id}\nCASE_ID: {case_id}\n"
        f"POLICY: {json.dumps(policy)}\n"
        f"TARGETS: {targets_str}\n"
        f"CONTEXT: {json.dumps(context)}\n"
        f"OBJECTIVES: {objectives or 'baseline'}\n"
        "TASK FORMAT: {\"task_id\", \"agent\", \"tool\", \"reason\", \"risk_level\", \"requires_approval\"}."
    )


# ---------------------------------------------------------------------------
# Plan validation
# ---------------------------------------------------------------------------

def _validate_targets_against_policy(targets: Dict[str, Any], policy: Dict[str, Any]) -> None:
    """Valida que targets est√©n dentro del scope de la policy."""
    scope = policy.get("scope", {})
    excluded = set(s.lower() for s in scope.get("excluded", []))
    allowed_domains = set(d.lower() for d in scope.get("domains", []))
    allowed_ips = set(ip.lower() for ip in scope.get("ips", []))
    allowed_clouds = set(c.lower() for c in scope.get("cloud", []))
    
    target_domains = targets.get("domains", [])
    target_ips = targets.get("ips", [])
    target_clouds = targets.get("cloud", [])
    
    # Verificar exclusiones
    for domain in target_domains:
        if domain.lower() in excluded:
            raise ValueError(f"Domain {domain} is in exclusion list")
    
    # Verificar scope (if restrictivo)
    if allowed_domains or allowed_ips or allowed_clouds:
        for domain in target_domains:
            if domain.lower() not in allowed_domains and not any(domain.lower().endswith(d.lower()) for d in allowed_domains if d.startswith("*")):
                logger.warning(f"Domain {domain} not in policy scope, but allowing")


def _validate_plan_against_policy(plan: Dict[str, Any], policy: Dict[str, Any]) -> None:
    """Valida plan vs policy. Lanza ValueError si viola restricciones."""
    forbidden_actions = set(a.lower() for a in policy.get("forbidden_actions", []))
    allowed_actions = set(a.lower() for a in policy.get("allowed_actions", []))
    approval_matrix = policy.get("approval_matrix", {})

    tasks = plan.get("tasks", [])
    if not isinstance(tasks, list) or not tasks:
        raise ValueError("Plan must include non-empty tasks list")

    for task in tasks:
        agent = str(task.get("agent", "")).lower()
        risk = str(task.get("risk_level", "LOW")).upper()
        if agent in forbidden_actions:
            raise ValueError("Plan includes forbidden action")
        if allowed_actions and agent not in allowed_actions:
            raise ValueError("Plan includes action not allowed by policy")
        if risk == "OFFENSIVE" and not approval_matrix.get("OFFENSIVE", False):
            raise ValueError("Offensive actions are not permitted by policy")


# ---------------------------------------------------------------------------
# Execution
# ---------------------------------------------------------------------------

async def execute_pentest_plan(
    pentest_id: str,
    case_id: str,
    action_plan: Dict[str, Any],
    policy: Dict[str, Any],
) -> Dict[str, Any]:
    """Ejecuta plan secuencialmente, respetando approvals y sandbox."""
    executor = ToolExecutor()
    tasks = action_plan.get("tasks", [])
    completed: List[Dict[str, Any]] = []
    failed: List[Dict[str, Any]] = []

    for task in tasks:
        task_id = task.get("task_id") or f"task-{len(completed)+len(failed)+1}"
        risk = str(task.get("risk_level", "LOW")).upper()
        requires_approval = bool(task.get("requires_approval")) or risk in {"MEDIUM", "HIGH", "OFFENSIVE"}

        if requires_approval:
            approval = await _request_human_approval(pentest_id, task)
            if not approval.get("approved"):
                failed.append({"task_id": task_id, "error": "NOT_APPROVED"})
                continue

        command = task.get("command") or _build_command_from_task(task)
        if not command:
            failed.append({"task_id": task_id, "error": "NO_COMMAND"})
            continue

        try:
            result = await executor.execute_sandboxed(
                execution_id=task_id,
                tool_id=task.get("tool", "unknown"),
                command=command,
                timeout=settings.PENTEST_TIMEOUT_SECONDS,
            )
            completed.append({"task_id": task_id, "result": result})
        except asyncio.TimeoutError:
            failed.append({"task_id": task_id, "error": "TIMEOUT"})
        except Exception as exc:  # pragma: no cover - general error path
            failed.append({"task_id": task_id, "error": str(exc)})

    total = len(completed) + len(failed)
    success_rate = int((len(completed) / total) * 100) if total else 0

    return {
        "pentest_id": pentest_id,
        "case_id": case_id,
        "total_tasks": total,
        "completed_tasks": completed,
        "failed_tasks": failed,
        "success_rate": success_rate,
        "evidence_path": str(_get_evidence_dir(case_id, pentest_id)),
    }


def _build_command_from_task(task: Dict[str, Any]) -> Optional[str]:
    """Construye comando simple a partir del task si no viene definido."""
    tool = task.get("tool")
    target = task.get("target") or task.get("host") or task.get("url")
    if not tool:
        return None
    if tool == "nmap" and target:
        return f"nmap {target}"
    if tool == "nuclei" and target:
        return f"nuclei -u {target}"
    return None


async def _request_human_approval(pentest_id: str, task: Dict[str, Any]) -> Dict[str, Any]:
    """Solicita aprobaci√≥n humana. Bloquea hasta que haya respuesta."""
    task_id = task.get("task_id", "")
    approval_request = {
        "pentest_id": pentest_id,
        "task_id": task_id,
        "status": "pending",
        "created_at": datetime.utcnow().isoformat(),
    }
    
    # Agregar a queue
    _approval_queue[pentest_id].append(approval_request)
    logger.info(f"‚è≥ Approval request queued for {pentest_id}:{task_id}")
    
    # En MVP, esperar con timeout (en producci√≥n: WebSocket/poll)
    max_wait = 300  # 5 minutos
    elapsed = 0
    while elapsed < max_wait:
        # Revisar si hay respuesta
        state = _pentest_state.get(pentest_id, {})
        approvals = state.get("approvals", [])
        for approval in approvals:
            if approval.get("task_id") == task_id:
                logger.info(f"‚úÖ Approval resolved for {pentest_id}:{task_id}: {approval.get('approved')}")
                return approval
        
        await asyncio.sleep(2)
        elapsed += 2
    
    # Timeout: rechazar
    logger.warning(f"‚ùå Approval timeout for {pentest_id}:{task_id}")
    return {"approved": False, "approved_by": "system", "task_id": task_id, "reason": "TIMEOUT"}


# ---------------------------------------------------------------------------
# Findings validation & reporting
# ---------------------------------------------------------------------------

def validate_and_correlate_findings(execution_results: Dict[str, Any]) -> Dict[str, Any]:
    """Valida hallazgos b√°sicos y devuelve estructura consolidada."""
    findings = []
    for item in execution_results.get("completed_tasks", []):
        result = item.get("result")
        if isinstance(result, dict):
            parsed = result.get("parsed")
            if parsed:
                findings.append(parsed)
    return {"validated_findings": findings, "total": len(findings)}


async def generate_pentest_report(
    pentest_id: str,
    case_id: str,
    execution_results: Dict[str, Any],
    validated_findings: Dict[str, Any],
    policy: Optional[Dict[str, Any]] = None,
) -> str:
    """Genera reporte markdown y devuelve ruta."""
    report_dir = _get_evidence_dir(case_id, pentest_id).parent / "report"
    report_dir.mkdir(parents=True, exist_ok=True)
    report_path = report_dir / "report.md"

    content = [
        f"# Pentest Report {pentest_id}",
        f"Case: {case_id}",
        f"Generated: {datetime.utcnow().isoformat()}Z",
        "",
        "## Executive Summary",
        f"- Total tasks: {execution_results.get('total_tasks', 0)}",
        f"- Success rate: {execution_results.get('success_rate', 0)}%",
        f"- Completed: {len(execution_results.get('completed_tasks', []))}",
        f"- Failed: {len(execution_results.get('failed_tasks', []))}",
        "",
        "## Policy",
        f"- Policy ID: {policy.get('policy_id', 'N/A') if policy else 'N/A'}",
        f"- Intensity: {policy.get('intensity', 'N/A') if policy else 'N/A'}",
        "",
        "## Findings",
        json.dumps(validated_findings, indent=2),
        "",
        "## Completed Tasks",
    ]
    
    for task in execution_results.get("completed_tasks", []):
        content.append(f"- {task.get('task_id')}: {task.get('result', {}).get('tool', 'unknown')} - Success")
    
    content.extend(["", "## Failed Tasks"])
    for task in execution_results.get("failed_tasks", []):
        content.append(f"- {task.get('task_id')}: {task.get('error', 'unknown error')}")
    
    report_path.write_text("\n".join(content))
    return str(report_path)


# ---------------------------------------------------------------------------
# Output parsing helpers
# ---------------------------------------------------------------------------

def _parse_tool_output(tool: str, output: str) -> Dict[str, Any]:
    tool = tool.lower()
    if tool == "nmap":
        open_ports = len(re.findall(r"\bopen\b", output))
        return {"tool": tool, "open_ports": open_ports, "raw": output.strip()}
    if tool == "nuclei":
        findings = [line for line in output.splitlines() if line.strip()]
        return {"tool": tool, "findings_count": len(findings), "raw": output.strip()}
    return {"tool": tool, "raw": output.strip()}


# ---------------------------------------------------------------------------
# Evidence utilities
# ---------------------------------------------------------------------------

def _get_evidence_dir(case_id: str, pentest_id: str) -> Path:
    base = settings.EVIDENCE_DIR / case_id / "analyses" / pentest_id / "pentest"
    base.mkdir(parents=True, exist_ok=True)
    return base


def _persist_plan(pentest_id: str, case_id: str, plan: Dict[str, Any], policy: Dict[str, Any], targets: Optional[Dict[str, Any]] = None) -> None:
    """Persiste plan, policy y targets a archivos JSON en directorio de evidencia."""
    evidence_dir = settings.EVIDENCE_DIR / case_id / "analyses" / pentest_id / "pentest"
    evidence_dir.mkdir(parents=True, exist_ok=True)
    
    # Guardar plan
    plan_path = evidence_dir / "plan.json"
    plan_path.write_text(json.dumps(plan, indent=2, default=str))
    logger.info(f"üìÑ Plan saved to {plan_path}")
    
    # Guardar policy
    policy_path = evidence_dir / "policy.json"
    # Limpiar policy (quitar secretos si existen)
    clean_policy = {k: v for k, v in policy.items() if k != "api_key"}
    policy_path.write_text(json.dumps(clean_policy, indent=2, default=str))
    logger.info(f"üìÑ Policy saved to {policy_path}")
    
    # Guardar targets
    if targets:
        targets_path = evidence_dir / "targets.json"
        targets_path.write_text(json.dumps(targets, indent=2, default=str))
        logger.info(f"üìÑ Targets saved to {targets_path}")


def _persist_approvals(pentest_id: str, case_id: str, approvals: List[Dict[str, Any]]) -> None:
    """Persiste aprobaciones a archivo JSON."""
    evidence_dir = settings.EVIDENCE_DIR / case_id / "analyses" / pentest_id / "pentest"
    approvals_path = evidence_dir / "approvals.json"
    approvals_path.write_text(json.dumps({"approvals": approvals}, indent=2, default=str))
    logger.info(f"üìÑ Approvals saved to {approvals_path}")


def _store_pentest_state(pentest_id: str, state: Dict[str, Any]) -> None:
    """Guarda estado de pentest en memoria (usar Redis en producci√≥n)."""
    _pentest_state[pentest_id] = state


def _get_pentest_state(pentest_id: str) -> Dict[str, Any]:
    """Obtiene estado de pentest desde memoria."""
    return _pentest_state.get(pentest_id, {})


def _add_approval(pentest_id: str, task_id: str, approved: bool, approved_by: str, comment: Optional[str] = None) -> None:
    """Agrega una aprobaci√≥n al estado del pentest."""
    state = _get_pentest_state(pentest_id)
    if "approvals" not in state:
        state["approvals"] = []
    
    approval = {
        "task_id": task_id,
        "approved": approved,
        "approved_by": approved_by,
        "approved_at": datetime.utcnow().isoformat(),
        "comment": comment,
    }
    state["approvals"].append(approval)
    _store_pentest_state(pentest_id, state)


# ---------------------------------------------------------------------------
# Orchestration entrypoint (optional)
# ---------------------------------------------------------------------------

async def run_autonomous_pentest(pentest_id: str, case_id: str, policy_id: str, objectives: Optional[str] = None) -> Dict[str, Any]:
    """Orquesta plan -> ejecuci√≥n -> validaci√≥n -> reporte."""
    policy = _load_pentest_policy(policy_id)
    plan = await plan_pentest_with_llm(pentest_id, case_id, policy_id, objectives)
    exec_results = await execute_pentest_plan(pentest_id, case_id, plan, policy)
    validated = validate_and_correlate_findings(exec_results)
    report_path = await generate_pentest_report(pentest_id, case_id, exec_results, validated)
    await update_case_status(case_id, status="completed", results=exec_results, summary=validated)
    return {"plan": plan, "results": exec_results, "report_path": report_path}


__all__ = [
    "plan_pentest_with_llm",
    "execute_pentest_plan",
    "validate_and_correlate_findings",
    "generate_pentest_report",
    "_validate_plan_against_policy",
    "_parse_tool_output",
]
