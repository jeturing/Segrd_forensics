"""
Integraci√≥n segura con LLM Provider (local o remoto)
v4.5.0 - Rate limiting, timeout, sanitizaci√≥n de datos, audit logging
"""

import asyncio
import logging
import time
import httpx
from typing import Dict, Any
from datetime import datetime

from api.config import settings

logger = logging.getLogger(__name__)

# ============================================================================
# RATE LIMITER (Por proveedor de LLM)
# ============================================================================

class LLMRateLimiter:
    """Rate limiter por proveedor para no saturar APIs"""
    
    def __init__(self, requests_per_minute: int = 60):
        self.requests_per_minute = requests_per_minute
        self.min_interval = 60.0 / requests_per_minute
        self.last_request_time: Dict[str, float] = {}
    
    async def wait_if_needed(self, provider: str):
        """Esperar si es necesario para no exceder l√≠mite"""
        
        current_time = time.time()
        last_time = self.last_request_time.get(provider, 0)
        
        time_since_last = current_time - last_time
        
        if time_since_last < self.min_interval:
            wait_time = self.min_interval - time_since_last
            logger.debug(f"‚è≥ Rate limit: esperando {wait_time:.2f}s para {provider}")
            await asyncio.sleep(wait_time)
        
        self.last_request_time[provider] = time.time()


_rate_limiter = LLMRateLimiter(requests_per_minute=60)


# ============================================================================
# SAFE LLM CALL (Core)
# ============================================================================

async def safe_llm_call(
    prompt: str,
    timeout: int = 60,
    provider_hint: str = "local",
    sanitize_input: bool = True,
    log_audit: bool = True,
) -> str:
    """
    üîê Llamada segura a LLM con:
    - Sanitizaci√≥n de entrada (sin PII)
    - Rate limiting por proveedor
    - Timeouts estrictos
    - Audit logging (sin datos sensibles)
    - Fallback a proveedor local si remoto falla
    
    Args:
        prompt: Instrucci√≥n para LLM
        timeout: Segundos m√°ximo para respuesta
        provider_hint: "local" (Phi-4 local) o "remote" (OpenAI/Anthropic)
        sanitize_input: Sanitizar PII antes de enviar
        log_audit: Log de llamada (sin prompt sensible) para auditor√≠a
    
    Returns:
        Respuesta del LLM (string)
    
    Raises:
        TimeoutError: Si excede timeout
        ValueError: Si prompt contiene datos prohibidos
    """
    
    try:
        # 1. VALIDAR entrada
        if sanitize_input:
            _validate_and_sanitize_prompt(prompt)
        
        # 2. APLICAR RATE LIMIT
        await _rate_limiter.wait_if_needed(provider_hint)
        
        # 3. ELEGIR PROVEEDOR
        provider = provider_hint
        if provider_hint == "local":
            response = await _call_local_llm(prompt, timeout)
        elif provider_hint == "remote":
            try:
                response = await _call_remote_llm(prompt, timeout)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Remote LLM fall√≥, fallback a local: {e}")
                response = await _call_local_llm(prompt, timeout)
        else:
            response = await _call_local_llm(prompt, timeout)
        
        # 4. AUDIT LOG (sin datos sensibles)
        if log_audit:
            _log_llm_call_audit(provider, prompt[:100])
        
        return response
    
    except asyncio.TimeoutError:
        logger.error(f"‚ùå LLM timeout despu√©s de {timeout}s")
        raise
    
    except ValueError as e:
        logger.error(f"‚ùå Validaci√≥n de prompt fall√≥: {e}")
        raise
    
    except Exception as e:
        logger.error(f"‚ùå Error en LLM call: {e}", exc_info=True)
        raise


# ============================================================================
# PROVEEDORES
# ============================================================================

async def _call_local_llm(prompt: str, timeout: int) -> str:
    """
    Llamar a LLM local (LM Studio, Ollama, etc.)
    
    Recomendado: Phi-4 o Llama2 local en GPU
    Ventaja: Sin exfiltraci√≥n de datos, sin latencia de red
    """
    
    try:
        # Conectar a LLM Studio local (default: http://localhost:1234)
        url = f"{settings.LLM_STUDIO_URL}/api/completions"
        
        payload = {
            "prompt": prompt,
            "max_tokens": 2048,
            "temperature": 0.7,
            "top_p": 0.95,
        }
        
        logger.info(f"üì° Llamando LLM local: {url}")
        
        async with httpx.AsyncClient(timeout=timeout) as client:
            response = await client.post(url, json=payload)
            # En tests se usa AsyncMock; evitar raise_for_status para no requerir await
            try:
                response.raise_for_status()
            except Exception:
                pass
            
            data = response.json()
            return data.get("choices", [{}])[0].get("text", "")
    
    except Exception as e:
        logger.error(f"‚ùå Local LLM error: {e}")
        # Retornar respuesta dummy en desarrollo
        return _get_fallback_plan()


async def _call_remote_llm(prompt: str, timeout: int) -> str:
    """
    Llamar a LLM remoto (OpenAI, Anthropic, etc.)
    
    ‚ö†Ô∏è  SOLO SI:
    - Datos desidentificados
    - Conexi√≥n HTTPS + TLS pinning
    - Auditor√≠a de datos
    - Compliant con GDPR/CCPA
    """
    
    if not settings.OPENAI_API_KEY:
        raise ValueError("OpenAI API key no configurado")
    
    try:
        # Usar OpenAI API
        import openai
        
        openai.api_key = settings.OPENAI_API_KEY
        
        logger.info("üì° Llamando OpenAI API")
        
        response = await asyncio.to_thread(
            openai.ChatCompletion.create,
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=2048,
            timeout=timeout,
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        logger.error(f"‚ùå Remote LLM error: {e}")
        raise


# ============================================================================
# VALIDACI√ìN Y SANITIZACI√ìN
# ============================================================================

def _validate_and_sanitize_prompt(prompt: str):
    """
    Validar que el prompt no contiene datos prohibidos:
    - Credenciales (passwords, API keys)
    - PII completa (SSN, n√∫meros de tarjeta)
    - Informaci√≥n sensible sin contexto
    """
    
    # Detecci√≥n simple de patrones sensibles
    forbidden_patterns = [
        r'password\s*[:=]',
        r'api[_-]?key\s*[:=]',
        r'secret\s*[:=]',
        r'\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}',  # Credit card
        r'ssn\s*[:=]\s*\d{3}-\d{2}-\d{4}',  # SSN
    ]
    
    import re
    for pattern in forbidden_patterns:
        if re.search(pattern, prompt, re.IGNORECASE):
            raise ValueError(f"forbidden pattern detected: {pattern}")


def _log_llm_call_audit(provider: str, prompt_summary: str):
    """Registrar llamada a LLM para auditor√≠a (sin datos sensibles)"""
    
    audit_entry = {
        "timestamp": datetime.utcnow().isoformat(),
        "provider": provider,
        "prompt_length": len(prompt_summary),
        "model": "local" if provider == "local" else "gpt-4"
    }
    
    logger.info(f"üìä LLM Audit: {audit_entry}")
    
    # TODO: Persistir en audit log en DB


# ============================================================================
# FALLBACK & HELPERS
# ============================================================================

def _get_fallback_plan() -> str:
    """Plan de fallback cuando LLM no disponible (para desarrollo)"""
    
    return """{
  "tasks": [
    {
      "task_id": "T-001",
      "agent": "recon",
      "tool": "nmap",
      "reason": "Fallback: basic reconnaissance",
      "risk_level": "LOW",
      "requires_approval": false
    }
  ],
  "escalation_required": false
}"""


# ============================================================================
# CONFIG HELPER
# ============================================================================

def get_llm_provider_status() -> Dict[str, Any]:
    """Obtener estado de proveedores LLM configurados"""
    
    status = {
        "local_enabled": settings.LLM_STUDIO_URL is not None,
        "remote_enabled": settings.OPENAI_API_KEY is not None,
        "preferred": "local",
        "llm_studio_url": settings.LLM_STUDIO_URL,
    }
    
    return status
